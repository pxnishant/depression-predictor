# -*- coding: utf-8 -*-
"""depressedornot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UjfAHZ1bfsIKRSBXvOzAcecB8aqfKQQV
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder
import joblib
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.compose import make_column_transformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('dataset.csv')
cols = ["id", "gender", "age", "city", "profession", "acad_pressure", "work_pressure", "cgpa", "study_satisfaction", "job_satisfaction", "sleep_duration", "dietary_habits", "degree", "suicidal_thoughts", "study_hours", "financial_stress", "family_history_mental_illness", "depression"]
num_cols = ['acad_pressure', 'work_pressure', 'cgpa', 'study_satisfaction', 'job_satisfaction', 'study_hours', 'financial_stress']

df.columns = cols

#cleaning data
df = df[df['profession'] == "Student"]
df = df[df['sleep_duration'] != "Others"]
df = df[df['degree'] != "Others"]
df = df[df['degree'] != "'Class 12'"]
df[num_cols] = df[num_cols].replace("?", np.nan)
df = df.drop(columns = ['profession'])

df['sleep_duration'] = df['sleep_duration'].apply(lambda x: x[1:-1])
df = df[df['city'].map(df['city'].value_counts()) >= 5]
df = df[df['degree'].map(df['degree'].value_counts()) >= 5]

df = df.dropna()

# binning

conditions = [
    df['age'] <= 15,
    df['age'].between(16, 20),
    df['age'].between(21, 25),
    df['age'].between(26, 30),
    df['age'].between(31, 35),
    df['age'] > 35
]

choices = ['<15', '16-20', '21-25', '26-30', '31-35', '>35']

df['age'] = np.select(conditions, choices, default='Unknown')

print("length of dataset", len(df))
# print(df['age'].value_counts())

for col in cols:
  if (col == 'profession'):
    continue
  print("---column name---", col)
  print(df[col].unique())

ohe_cols = ["age", "gender", "city", "degree", "suicidal_thoughts", "family_history_mental_illness"]
ode_cols = ['sleep_duration', 'dietary_habits']
ode_categories = [
    ['5-6 hours', 'Less than 5 hours', '7-8 hours', 'More than 8 hours'],
    ['Healthy', 'Moderate', 'Unhealthy', 'Others']
]

ohe = OneHotEncoder(sparse_output = False)
ode = OrdinalEncoder(categories = ode_categories)

ct = make_column_transformer(
    (ohe, ohe_cols),
    (ode, ode_cols),
    (StandardScaler(), num_cols),
    remainder="passthrough"
)
# ct.set_output(transform = "pandas")
# tdf = ct.fit_transform(df)

# tdf.head()

#splitting
# target_col = "remainder__depression"
target_col = "depression"


# y = tdf[target_col]
# X = tdf.drop(columns=[target_col])


y = df[target_col]
X = df.drop(columns=[target_col])


X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.4, random_state=42, stratify=y  #stratify to keep class distribution same
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

# print(f"Train size: {(y_train == 1).sum()}")
# print(f"Train size: {len(y_train)}")
# print(f"Test size: {len(X_test)}")

print(y_test)
print(y_train.value_counts(normalize=True))

logreg_pipeline = Pipeline([
    ('preprocessor', ct),
    ('logreg', LogisticRegression(max_iter=1000, random_state=42))
])

logreg_pipeline.fit(X_train, y_train)

joblib.dump(logreg_pipeline, "pipeline.pkl")

y_test_pred = logreg_pipeline.predict(X_test)

print(classification_report(y_test, y_test_pred))